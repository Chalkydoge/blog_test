---
title: 机器学习作业-欺诈识别
date: 2022-11-24 22:49:20
tags:
- 机器学习
---

令人吐血的作业...

<!--more-->

<!-- {% asset_img (url_here) description %} -->

背景: 


数据:
本次数据源有3份：
- driver_data，建模样本表，每行数据是一笔交易，数据可以分为几部分：交易主键，交易主体，交易属性，数值型变量，行为序列编码，是否欺诈的标签；

- event_data_card，driver数据中收益卡近15天(从driver表中的交易时间算起)的历史收款数据，包含交易主键，交易主体，交易属性；

- event_data_user，driver数据中用户近15天的历史付款数据，包含交易主键，交易主体，交易属性（注意这里的付款场景不止转账到卡的交易数据）；


评判标准:
提交结果为每个测试样本是1的概率，也就是is_fraud为1的概率。评价方法为3个打扰率下欺诈金额的召回比例的加权（越大越好），打扰率为0.005，0.01，0.05，加权系数分别为0.4，0.3，0.3。

举例：
假设我们有10000个样本，100个欺诈样本，欺诈金额200，打扰率0.01相当于欺诈概率靠前的10000*0.01=100个样本入围，假设这100个样本中有50个欺诈样本，涉及欺诈金额150，则打扰率0.01的覆盖欺诈金额比例为150/200=0.75


关键点:

1. 特征工程: 提取重要的特征, 重新组成一些新特征&去掉一些特别离谱的数据

2. 模型选择：决策树/随机森林一般不错

3. 正负类差距过大 => imblearn进行适当修正 或者使用负采样的方式 提升负类比例 down-sampling

### 特征工程

做特征的思路

因为是识别当前交易是否为欺诈交易，在做特征之前可能需要基于一定的业务背景分析下欺诈的场景，一般来讲，线上支付欺诈一般是盗号，那么实施欺诈时可能会有两种表现

1. 盗取后，集中高频交易，从而在最短时间内套现;

2. 模拟真实用户的交易特征，在尽可能不被系统和用户发现的前提下实现盗刷等;

本次数据源有3份：


- `driver_data`，建模样本表，每行数据是一笔交易，数据可以分为几部分：交易主键，交易主体， 交易属性，数值型变量，行为序列编码，是否欺诈的标签；

- `event_data_card`， driver数据中收益卡近15天(从driver表中的交易时间算起)的历史收款数据，包含交易主键，交易主体，交易属性；

- `event_data_user`，driver数据中用户近15天的历史付款数据，包含交易主键，交易主体， 交易属性（注意这里的付款场景不止转账到卡的交易数据）；

交易属性
- 交易时间

- 交易的用户(用户id)

- 收款方id(b_id, c_id)等

- 交易用户信息(基本属性)

- 收款方信息(收款为账号) b_info_1

- 收款方信息(收款为卡) c_info_1

- 用户信息 a_info_1, a_info_2, a_info_3

- 交易的设备位置信息 e_info2, e_info3


总结一下:
给我们的driver_data数据表中的数据主要就是以下这些

1. 发起交易的用户信息

2. 收款方信息, 这里包含了两种收款方

- 收款方为卡

- 收款方为体系内账号

3. 交易双方的设备位置信息

4. 交易发生的时间(时间+日期+消失)

5. 交易金额

6. 交易是否完成


可以提取的特征例如:

1. 观察收款方的特点, 是否与诈骗率有关系?
- 收款为卡和收款为账号

2. GPS位置信息与诈骗率关系

3. ...


### 提取特征

- 去除了7列无关紧要的数据列(这里主要是用户信息, 因为无论是在训练集和还是测试集都没用!)

- 去掉了训练集中所有被系统拦截的交易(if_succ = -1)这些全部去掉 总共900+行数据.

- 在XGBoost模型下反而降低了ROC-AUC到82%(性能变差了! 说明好像去掉了什么重要的内容!)

可能的改进方案:

- 时间序列数据 在训练+测试集上是有一个明显的先后顺序的!

todo:

1. dt 一项实际上和time有重复! (time包含了当天的小时+分钟+秒等信息)

> apply自定义时间(YY MM DD: hh:mm:ss to 时间戳整数)

将time转为时间戳, 去掉dt(重复了), 序列化week_day(0-1-2-3-4-5-6)表示星期天-星期六即可, hh小时可以不用改

2. 增加特征, 替换time(绝对时间)

time_in_day 表示天内的时间偏移量

cents 表示 交易金额取整之后剩余部分()

> df['time_in_day'] = uni.TransactionDT % 86400
  df['cents'] = uni.TransactionAmt % 1

3. 使用lgb替代原先使用的XGBoost(实际上可以两种都使用)

4. 借鉴他人的方案

我认为这个或许可以替代手工实现一波特征的生成(引用openfe的feature-generation方法)

> https://github.com/IIIS-Li-Group/OpenFE/blob/master/examples/IEEE-CIS-Fraud-Detection/main.py

或者这个比较传统的方式
> https://www.kaggle.com/code/jtrotman/ieee-fraud-adversarial-lgb-split-points

- Cached OOF(Out-Of-Fold) 折外预测
- FAST Cross

### 特征分析

用户信息

a_id_1 + a_info_1-7

- a_info_4, a_info_6 这两列明显种类数量较少 适合使用Onehot编码

- 其余的a_info3,5,7等的量级在70-350之间 可以正常使用label-encoding

- a_id_1这个用户标识几乎没有重复的, 让人怀疑究竟是怎会做到的, 即使存在诈骗行为也是很多的人(切换不同的账号进行诈骗)


#### 发起交易方的用户信息数据列


**用户信息** 主要是以下这些列相关的信息

- ['a_id_1', 'a_info_1', 'a_info_2', 'a_info_3', 'a_info_4', 'a_info_5', 'a_info_6', 'a_info_7']

a_id_1基本上都不相同(基本上都是不同的用户)
a_info_[1-7] 这些给出的都是uuid编码数据 看得出来比较分散, 需要LABEL-ENCODING后进行处理

#### 地理位置相关的参数

- ['e_info_2','e_info_3','e_info_4','e_info_5']

4个编码字符串 类别化之后是否可以发现一些关系?

注意是否需要和测试集一起编码?

#### 收款方相关的参数

收款方是**用户**

- ['b_id_1','b_info_1', 'b_info_2', 'b_info_3', 'b_info_4', 'b_info_5']

总结: 根本就没有, 可以忽略


收款方是 **卡**

- ['c_id_1', 'c_info_1', 'c_info_2', 'c_id_2', 'c_info_4', 'c_info_5']

很多的编码字符串 类别化之后是否可以发现一些关系?

注意是否需要和测试集一起编码?

我认为有必要先划分driver data成两半
- 收款是用户的 merge 用户

- 收款是卡的 merge 卡

然后分别在对应的主体上生成模型, 最后进行评估

c_id_1 不清楚 23个相同用户 保留

c_id_2 不清楚 911个共同特征 保留

c_info_1 也可以留着(虽然关联不大 272个共同标签

c_info_2 可以保留

c_info_3 这个好多空值 建议去掉

c_info_4 可以保留

c_info_5 可以保留

#### 交易相关参数

这些:

['time', 'hh', 'week_day','e_info_6','e_info_13','if_succ', 'dt']

e_info_6 反映了交易类型(完全一致)

e_info_13 标识了交易金额相关


- if_succ = 0的案例可以丢到(防止影响)

- time其实没什么用(看起来) 测试集合的时间都在训练集合后面

- e_info_6这一列数据在测试集合和训练集合一模一样 去掉

- hh和week_day还是比较有用的

- e_info_13分布相近 可以利用

- dt同理 没有什么用

#### 总结

这一些参数内部 可以被作为'类别category'的列有以下:
```
```

而剩余的non-numeric列自然成为了'ordinal_features'

------

通过open_fe的特征生成, 使得最终成绩提高到了0.34, 说明很有效果(特征的选择)

继续提升的话需要考虑更精细的特征组合(高维度的特征加入)
模型继续使用随机森林

1. 比如组合"地理信息", "用户信息"为新标签列加入数据集
2. 加入一些_FREQUENCY列(例如某一个标签出现的频率)
3. 细分AMOUNT(包括零头部分)